{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bhaavvya/Android_Malware_Detection/blob/onegram_file/OneGramClassifierFinalized.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bbZwTXr-RTs3"
      },
      "source": [
        "Importing the Libraries"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cnQtVoLT_1ti",
        "outputId": "e2215ef1-5f6d-4442-f6dc-29ffb7261d6a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "twhheMOWRKQ2"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.pipeline import Pipeline"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CVXpUS8VRjeR"
      },
      "source": [
        "Data Pre-processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OkDOBGvpRc72"
      },
      "source": [
        "# Importing the dataset\n",
        "dataset = pd.read_csv('/content/drive/MyDrive/mp/onegram.csv')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xCgYSe2FRtiF"
      },
      "source": [
        "#Dependent and Independent Variables\n",
        "X = dataset.iloc[:, 1]\n",
        "y = dataset.iloc[:, 2]"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7l_YNFpqR5X8",
        "outputId": "b7bf9191-49dc-4b33-fabc-48670fe12f98"
      },
      "source": [
        "X.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    ['sput-object', 'return-void', 'invoke-direct'...\n",
              "1    ['invoke-direct', 'return-void', 'iput-object'...\n",
              "2    ['invoke-direct', 'return-void', 'const-string...\n",
              "3    ['invoke-direct', 'return-void', 'nop', 'invok...\n",
              "4    ['invoke-direct', 'return-void', 'sget-object'...\n",
              "Name: Onegram, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L143KTRDSDef",
        "outputId": "8ebc9977-f2fa-49b9-b3a8-3baf251fbce9"
      },
      "source": [
        "y.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    Adware\n",
              "1    Trojan\n",
              "2    Trojan\n",
              "3    Benign\n",
              "4    Adware\n",
              "Name: Label, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MA0JCtmDSPH_"
      },
      "source": [
        "# Encoding categorical data\n",
        "# Encoding the Independent Variable\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "vectorizer = TfidfVectorizer(ngram_range = (1,1),max_features=1000)\n",
        "X = vectorizer.fit_transform(X)\n",
        "\n",
        "# Encoding the Dependent Variable\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "labelencoder_y = LabelEncoder()\n",
        "y = labelencoder_y.fit_transform(y)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install --upgrade keras\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tuespBm7Amx5",
        "outputId": "0e9bceb7-b7e3-4860-bfb2-bc653482f0fb"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Collecting keras\n",
            "  Downloading keras-3.0.5-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from keras) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras) (1.25.2)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras) (13.7.1)\n",
            "Collecting namex (from keras)\n",
            "  Downloading namex-0.0.7-py3-none-any.whl (5.8 kB)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras) (3.9.0)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.10/dist-packages (from keras) (0.1.8)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.10/dist-packages (from keras) (0.2.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras) (2.16.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n",
            "Installing collected packages: namex, keras\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.15.0\n",
            "    Uninstalling keras-2.15.0:\n",
            "      Successfully uninstalled keras-2.15.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.15.0 requires keras<2.16,>=2.15.0, but you have keras 3.0.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed keras-3.0.5 namex-0.0.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yMhwFxA_vzUf"
      },
      "source": [
        "#To convert Labels in One-Hot Encoding Form (Binary Matrix)\n",
        "#from keras.utils.np_utils import to_categorical\n",
        "#y=to_categorical(y,len(labelencoder_y.classes_))"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "y = to_categorical(y, num_classes=len(labelencoder_y.classes_))\n"
      ],
      "metadata": {
        "id": "rrhvSVDkBFoW"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cJzn-fjnS5iw"
      },
      "source": [
        "# Splitting the dataset into the Training set and Test set\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X.toarray(), y, test_size = 0.25, random_state = 101)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_cuzcZxLy6_3"
      },
      "source": [
        "# Feature Scaling\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q7Uw6ZJOUMYR"
      },
      "source": [
        "Fitting Classification Model\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import Dropout, LSTM, Dense\n",
        "from keras.models import Sequential\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "# Assuming X_train and y_train are your training data\n",
        "x_train = X_train.reshape(-1, 1, X_train.shape[1])\n",
        "\n",
        "# Adding LSTM layer and some Dropout regularisation\n",
        "model.add(LSTM(100, return_sequences=True, input_shape=(x_train.shape[1], x_train.shape[2])))\n",
        "# Adding a Dropout Layer\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "# Output layer with adjusted shape\n",
        "model.add(Dense(4, activation='softmax'))  # Adjust the number of units according to your problem\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "dyoQxJ-pBXFa"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jf7vabwlUXfY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b35e2d0-70a3-4a96-ab72-0fcb86f394a7"
      },
      "source": [
        "# Predicting the Test set results\n",
        "y_pred = np.argmax(model.predict(X_test.reshape(-1, 1, X_test.shape[1])) ,axis=1)\n",
        "y_test = np.argmax(y_test,axis=1)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jrnKh7KPzg9t"
      },
      "source": [
        "Retransforming Labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KxAgqow7zWFk"
      },
      "source": [
        "#now if we want to get back classes from pred of RF\n",
        "\n",
        "#labelencoder_y.inverse_transform(y_pred)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Assuming labelencoder_y is your LabelEncoder\n",
        "# and y_pred is the output of your model\n",
        "\n",
        "# Convert one-hot encoded predictions to class indices\n",
        "class_indices = np.argmax(y_pred, axis=1)\n",
        "\n",
        "# Use inverse_transform on the 1D array\n",
        "predicted_classes = labelencoder_y.inverse_transform(class_indices)\n",
        "# Get the number of unique classes\n",
        "num_classes = len(np.unique(predicted_classes))\n",
        "\n",
        "print(\"Number of Classes:\", num_classes)"
      ],
      "metadata": {
        "id": "jsotY_CgLuW5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c15242e-3385-414d-c2a1-ff981c3fcbc5"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Classes: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Shape of y_pred:\", y_pred.shape)\n",
        "print(\"Shape of class_indices:\", class_indices.shape)\n",
        "print(\"Class Indices:\", class_indices)\n",
        "print(\"Predicted Classes:\", predicted_classes)\n",
        "\n"
      ],
      "metadata": {
        "id": "gX4S6I-oM04e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "809dc268-f5be-4c58-ef7c-2c5abd12dd08"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of y_pred: (710, 4)\n",
            "Shape of class_indices: (710,)\n",
            "Class Indices: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0]\n",
            "Predicted Classes: ['Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware'\n",
            " 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware'\n",
            " 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware'\n",
            " 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware'\n",
            " 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware'\n",
            " 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware'\n",
            " 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware'\n",
            " 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware'\n",
            " 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware'\n",
            " 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware'\n",
            " 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware'\n",
            " 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware'\n",
            " 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware'\n",
            " 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware'\n",
            " 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware'\n",
            " 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware'\n",
            " 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware'\n",
            " 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware'\n",
            " 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware'\n",
            " 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware'\n",
            " 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware'\n",
            " 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware'\n",
            " 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware'\n",
            " 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware'\n",
            " 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware'\n",
            " 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware'\n",
            " 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware'\n",
            " 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware'\n",
            " 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware'\n",
            " 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware'\n",
            " 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware'\n",
            " 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware'\n",
            " 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware'\n",
            " 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware'\n",
            " 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware'\n",
            " 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware'\n",
            " 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware'\n",
            " 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware'\n",
            " 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware'\n",
            " 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware'\n",
            " 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware'\n",
            " 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware'\n",
            " 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware'\n",
            " 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware'\n",
            " 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware'\n",
            " 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware'\n",
            " 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware'\n",
            " 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware'\n",
            " 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware'\n",
            " 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware'\n",
            " 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware'\n",
            " 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware'\n",
            " 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware'\n",
            " 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware'\n",
            " 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware'\n",
            " 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware'\n",
            " 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware'\n",
            " 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware'\n",
            " 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware'\n",
            " 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware'\n",
            " 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware'\n",
            " 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware'\n",
            " 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware'\n",
            " 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware'\n",
            " 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware'\n",
            " 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware'\n",
            " 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware'\n",
            " 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware'\n",
            " 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware'\n",
            " 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware'\n",
            " 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware'\n",
            " 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware'\n",
            " 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware'\n",
            " 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware'\n",
            " 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware'\n",
            " 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware'\n",
            " 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware'\n",
            " 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware'\n",
            " 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware'\n",
            " 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware'\n",
            " 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware'\n",
            " 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware'\n",
            " 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware'\n",
            " 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware'\n",
            " 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware'\n",
            " 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware'\n",
            " 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware'\n",
            " 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware'\n",
            " 'Adware' 'Adware' 'Adware' 'Adware' 'Adware' 'Adware']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Unique Predicted Classes:\", np.unique(predicted_classes))\n",
        "# Assuming X_train and X_val are your training and validation data\n",
        "print(\"Training Sample Classes:\", np.unique(labelencoder_y.inverse_transform(y_train[:10])))\n",
        "print(\"Validation Sample Classes:\", np.unique(labelencoder_y.inverse_transform(y_val[:10])))\n",
        "# Assuming model is your trained model\n",
        "_, train_accuracy = model.evaluate(x_train, y_train)\n",
        "print(\"Training Accuracy:\", train_accuracy)\n",
        "model.summary()\n",
        "# Assuming y_train is your training labels\n",
        "unique_classes, class_counts = np.unique(labelencoder_y.inverse_transform(y_train), return_counts=True)\n",
        "print(\"Class Distribution in Training Data:\")\n",
        "for cls, count in zip(unique_classes, class_counts):\n",
        "    print(f\"{cls}: {count} samples\")\n"
      ],
      "metadata": {
        "id": "Zi2QEpWENtLP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "outputId": "464baadd-6189-4d80-a6f0-9700b196b130"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique Predicted Classes: ['Adware']\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "y should be a 1d array, got an array of shape (10, 4) instead.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-6d1cecde32c2>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Unique Predicted Classes:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# Assuming X_train and X_val are your training and validation data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training Sample Classes:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabelencoder_y\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Validation Sample Classes:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabelencoder_y\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Assuming model is your trained model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_label.py\u001b[0m in \u001b[0;36minverse_transform\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m    153\u001b[0m         \"\"\"\n\u001b[1;32m    154\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m         \u001b[0;31m# inverse transform of empty array is empty array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcolumn_or_1d\u001b[0;34m(y, dtype, warn)\u001b[0m\n\u001b[1;32m   1200\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_asarray_with_order\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"C\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1202\u001b[0;31m     raise ValueError(\n\u001b[0m\u001b[1;32m   1203\u001b[0m         \u001b[0;34m\"y should be a 1d array, got an array of shape {} instead.\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1204\u001b[0m     )\n",
            "\u001b[0;31mValueError\u001b[0m: y should be a 1d array, got an array of shape (10, 4) instead."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming model is your trained model\n",
        "# Assuming y_train is your training labels in one-hot encoded form\n",
        "\n",
        "# Convert one-hot encoded training labels back to class indices\n",
        "class_indices_train = np.argmax(y_train, axis=1)\n",
        "\n",
        "# Get predictions from the model\n",
        "y_pred = model.predict(x_train)\n",
        "\n",
        "# Ensure the shapes match\n",
        "if y_train.shape[1] == y_pred.shape[1]:\n",
        "    # Continue with your evaluation or other tasks\n",
        "    # ...\n",
        "\n",
        "# If you encounter the same issue with evaluation, convert y_train back to class indices\n",
        "  class_indices_test = np.argmax(y_test, axis=1)\n",
        "  print(\"hi\")\n",
        "\n",
        "# Evaluate the model using class indices\n",
        "  _, accuracy = model.evaluate(X_test, to_categorical(class_indices_test, num_classes=len(labelencoder_y.classes_)))\n",
        "  print(\"Accuracy:\", accuracy)\n"
      ],
      "metadata": {
        "id": "DbvYTWPZOVK-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8382346-7ab5-4562-dcd6-79ae6cca3ae9"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming y_train_original is your original class labels\n",
        "y_train_original = labelencoder_y.inverse_transform(y_train)\n",
        "print(\"Original Classes:\", y_train_original[:10])\n",
        "print(\"Predicted Classes:\", predicted_classes[:10])\n"
      ],
      "metadata": {
        "id": "sPjpQ0u-N13v",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "outputId": "f03e703b-9594-455e-9efa-fe17b4c979d2"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "y should be a 1d array, got an array of shape (2130, 4) instead.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-d7aa2a23f9f1>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Assuming y_train_original is your original class labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0my_train_original\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabelencoder_y\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Original Classes:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_original\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Predicted Classes:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted_classes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_label.py\u001b[0m in \u001b[0;36minverse_transform\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m    153\u001b[0m         \"\"\"\n\u001b[1;32m    154\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m         \u001b[0;31m# inverse transform of empty array is empty array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcolumn_or_1d\u001b[0;34m(y, dtype, warn)\u001b[0m\n\u001b[1;32m   1200\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_asarray_with_order\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"C\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1202\u001b[0;31m     raise ValueError(\n\u001b[0m\u001b[1;32m   1203\u001b[0m         \u001b[0;34m\"y should be a 1d array, got an array of shape {} instead.\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1204\u001b[0m     )\n",
            "\u001b[0;31mValueError\u001b[0m: y should be a 1d array, got an array of shape (2130, 4) instead."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C_qtRGxDUj2b"
      },
      "source": [
        "Model Performance Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MdUKxpDBUzj5"
      },
      "source": [
        "#Accuracy Score\n",
        "from sklearn import metrics\n",
        "print(\"Accuracy Score: \", metrics.accuracy_score(y_test, y_pred))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Assuming y_test is not one-hot encoded\n",
        "y_test_one_hot = to_categorical(y_test, num_classes=num_classes)  # num_classes is the number of classes in your problem\n",
        "\n",
        "# Now you can use y_test_one_hot and y_pred for accuracy calculation\n",
        "accuracy = metrics.accuracy_score(y_test_one_hot, y_pred)\n",
        "print(\"Accuracy Score: \", accuracy)\n"
      ],
      "metadata": {
        "id": "o9LMYPzhMQlu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1AW5U3AzekpY"
      },
      "source": [
        "Save the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pr_Ni32K-i7I"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.subplot(2,1,1)\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.title('Model Acuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend(['one-gram'], loc='upper left')\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CPpM-nbHej-E"
      },
      "source": [
        "from keras.models import model_from_json\n",
        "model_json = model.to_json()\n",
        "with open(\"model_onegram_lstm.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)\n",
        "# serialize weights to HDF5\n",
        "model.save_weights(\"model_onegram_lstm.h5\")\n",
        "print(\"Saved model to disk\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}